{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "Regression is a type of supervised learning technique used to predict a continuous outcome variable based on one or more predictor variables. It is commonly used for forecasting and finding relationships between variables. It is basically a statistical method that helps us to predict the relationship between the variables.\n",
    "\n",
    "Regression -\n",
    "- Describes how one variable **dependent variable** is changed by the change of **independent variable**.\n",
    "- Can be linear or non-linear depending on the relationship between variables.\n",
    "- Helps in identifying trends and making predictions based on historical data.\n",
    "- Commonly used algorithms include Linear Regression, Polynomial Regression, and Ridge Regression.\n",
    "- Plays a crucial role in various fields such as finance, healthcare, and marketing.\n",
    "\n",
    "\n",
    "\n",
    "| ![image.png](https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/images/Least_squares_example.png) |\n",
    "|:--:|\n",
    "| *Figure-1: An example of regression visualization* |\n",
    "\n",
    "**Figure-1** illustrates the rate of change of the dependent variable **Mass** with respect to the independent variable **Time**. This relationship between the variables allows us to predict future points on the graph, beauty of the regression analysis. However, not all data points perfectly align with this line. Some points lie significantly above or below itâ€”these are called **Outliers**. Outliers are observations that differ markedly from the expected trend due to various reasons, such as measurement errors, natural variability, or unexpected external influences. Identifying and analyzing outliers is crucial because they can impact the accuracy of predictions and the overall reliability of the regression model.\n",
    "\n",
    "### Types of Regression\n",
    "\n",
    "- **Linear Regression**: Establishes a linear relationship between the dependent and independent variables. It assumes that the change in the dependent variable is proportional to the change in the independent variable.\n",
    "- **Polynomial Regression**: Extends linear regression by fitting a polynomial equation to the data, allowing for modeling of non-linear relationships.\n",
    "- **Logistic Regression**: Used for binary classification problems, it predicts the probability of a categorical dependent variable.\n",
    "- **Ridge Regression**: A type of linear regression that includes a [regularization](https://www.geeksforgeeks.org/regularization-in-machine-learning/) term to prevent overfitting by penalizing large coefficients.\n",
    "- **Lasso Regression**: Similar to Ridge Regression but uses [L1 regularization](https://www.geeksforgeeks.org/regularization-in-machine-learning/), which can shrink some coefficients to zero, effectively performing feature selection.\n",
    "- **Elastic Net Regression**: Combines [L1 and L2 regularization](https://www.geeksforgeeks.org/regularization-in-machine-learning/) techniques to balance feature selection and coefficient shrinkage.\n",
    "- **Stepwise Regression**: A method of fitting regression models by adding or removing predictors based on their statistical significance.\n",
    "- **Quantile Regression**: Focuses on estimating the conditional quantiles of the response variable, useful for understanding the impact of predictors on different points of the distribution.\n",
    "\n",
    "***Note***: Currently for our **SMMS** understanding of `Linear regression`, `Logistic regression` and `Polynomial regression` is far enough. But in future if any other algrithm is needed then we may proceed with that.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
